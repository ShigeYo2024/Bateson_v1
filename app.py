
import streamlit as st
import openai

# Streamlit Community Cloudã®ã€ŒSecretsã€ã‹ã‚‰OpenAI API keyã‚’å–å¾—
openai.api_key = st.secrets.OpenAIAPI.openai_api_key

# st.session_stateã‚’ä½¿ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿å­˜
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": """ã‚ãªãŸã¯ã‚°ãƒ¬ã‚´ãƒªãƒ¼ãƒ»ãƒ™ã‚¤ãƒˆã‚½ãƒ³ã®æ•™è‚²ãƒ¢ãƒ‡ãƒ«ã«ç¿’ç†Ÿã—ãŸæ•™è‚²ã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’åŸºã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨å¯¾è©±ã—ã¦ãã ã•ã„ï¼š
1. ç¾åœ¨ã®çŠ¶æ³ã‚’ç†è§£ã™ã‚‹è³ªå•ã‚’ã™ã‚‹ã€‚
2. å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãã€é©åˆ‡ãªåŠ©è¨€ã‚’æä¾›ã™ã‚‹ã€‚
3. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã—ã€å†…çœã‚’ä¿ƒã™ã€‚"""}
        ]

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
def communicate():
    messages = st.session_state["messages"]

    user_message = {"role": "user", "content": st.session_state["user_input"]}
    messages.append(user_message)

    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=messages
    )

    bot_message = response["choices"][0]["message"]
    messages.append(bot_message)

    st.session_state["user_input"] = ""  # å…¥åŠ›æ¬„ã‚’æ¶ˆå»


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®æ§‹ç¯‰
st.title("AI Coach SHIGERU")
st.write("ã‚°ãƒ¬ã‚´ãƒªãƒ¼ãƒ»ãƒ™ã‚¤ãƒˆã‚½ãƒ³ã®æ•™è‚²ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦ã€ChatGPTã«ã‚ˆã‚‹â€ãƒ¡ã‚¿èªçŸ¥â€ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™")

user_input = st.text_input("ã©ã‚“ãªã“ã¨ã‚’å­¦ã³ãŸã„ã®ã‹ã€æ˜¯éæ•™ãˆã¦ãã ã•ã„ã€‚", key="user_input", on_change=communicate)

if st.session_state["messages"]:
    messages = st.session_state["messages"]

    for message in reversed(messages[1:]):  # ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šã«
        speaker = "ğŸ™‚"
        if message["role"]=="assistant":
            speaker="ğŸ¤–"

        st.write(speaker + ": " + message["content"])


#  å±¥æ­´ã®ä¿å­˜ã‚’å¯èƒ½ã«ã™ã‚‹
import json

# ä¿å­˜æ©Ÿèƒ½
def save_history():
    with open("chat_history.json", "w") as file:
        json.dump(st.session_state["messages"], file)

# ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
def load_history():
    try:
        with open("chat_history.json", "r") as file:
            st.session_state["messages"] = json.load(file)
    except FileNotFoundError:
        st.session_state["messages"] = [
            {"role": "system", "content": """ã‚ãªãŸã¯ã‚°ãƒ¬ã‚´ãƒªãƒ¼ãƒ»ãƒ™ã‚¤ãƒˆã‚½ãƒ³ã®æ•™è‚²ãƒ¢ãƒ‡ãƒ«ã«ç¿’ç†Ÿã—ãŸæ•™è‚²ã‚³ãƒ¼ãƒã§ã™ã€‚..."""}
        ]

# èµ·å‹•æ™‚ã«å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰
if "messages" not in st.session_state:
    load_history()
# ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚ã«ä¿å­˜
if st.button("çµ‚äº†ã—ã¦å±¥æ­´ã‚’ä¿å­˜"):
    save_history()
    st.success("å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
def communicate():
    messages = st.session_state["messages"]
    
    # å…¥åŠ›ãŒç©ºã®å ´åˆ
    if not st.session_state["user_input"].strip():
        st.warning("å…¥åŠ›ãŒç©ºã§ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return

    user_message = {"role": "user", "content": st.session_state["user_input"]}
    messages.append(user_message)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages
        )
        bot_message = response["choices"][0]["message"]
        messages.append(bot_message)
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    st.session_state["user_input"] = ""

# åˆ†æé–¢æ•°ã®è¿½åŠ 
def analyze_messages():
    levels = {"zero_learning": 0, "first_learning": 0, "second_learning": 0, "third_learning": 0}
    for msg in st.session_state["messages"]:
        if msg["role"] == "assistant":
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã«å¿œã˜ã¦åˆ†é¡ (ä»®ã®ä¾‹)
            if "åŸºæœ¬çŸ¥è­˜" in msg["content"]:
                levels["zero_learning"] += 1
            elif "æ–°ã—ã„æ–¹æ³•" in msg["content"]:
                levels["first_learning"] += 1
            elif "è€ƒãˆæ–¹ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³" in msg["content"]:
                levels["second_learning"] += 1
            elif "ä¸–ç•Œè¦³" in msg["content"]:
                levels["third_learning"] += 1
    return levels

if st.button("å¯¾è©±ã®ã‚µãƒãƒªãƒ¼ã‚’è¦‹ã‚‹"):
    analysis = analyze_messages()
    st.write("å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã”ã¨ã®ã‚„ã‚Šå–ã‚Šæ•°:", analysis)

# Rustã‚’ä½¿ã‚ãªã„
from transformers import pipeline

# Use without tokenizers
model = pipeline('text-classification', use_fast=False)

